# Chinchilla

**Chinchilla** is a web-based AI chatbot application built to explore the vulnerabilities of Large Language Models (LLMs), especially Prompt Injection. 

Can you use prompt injection and gain code execution on the application?

![image](https://github.com/user-attachments/assets/198b8a58-6da3-4741-ae22-db837e0de09f)

## ðŸš€ Getting Started

Try to not look at the source code first for the fun!

### 1. Clone the repo

```bash
git clone https://github.com/EDMPL/Chinchilla.git
cd Chinchilla
```
### 2. Setup Virtual Environment
Create venv: ```python -m venv venv```

Activate (Linux / MacOS): ```source ./venv/bin/activate```

Activate (Windows): ```.\venv\Scripts\activate```

### 2. Install the requirements

```pip install -r requirements.txt```

### 3. Run the application
```python chinchilla.py```

### 4. Hack the application!
http://127.0.0.1:8000/chinchilla

<img width="1435" height="802" alt="Screenshot 2025-07-11 at 08 57 09" src="https://github.com/user-attachments/assets/c7641596-98a4-4815-a19a-e8e820197595" />

Please note that it may take a while for the chatbot to generate a response, especially for the first few attempts.
