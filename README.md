# Chinchilla

**Chinchilla** is a web-based AI chatbot application built to explore the vulnerabilities of Large Language Models (LLMs), especially Prompt Injection. 

Can you use prompt injection and gain code execution on the application?

![image](https://github.com/user-attachments/assets/198b8a58-6da3-4741-ae22-db837e0de09f)

## ðŸš€ Getting Started

Key parts of the code are obfuscated to keep the challenge fun, please try solving it without peeking at the source!

### 1. Clone the repo

```bash
git clone https://github.com/EDMPL/Chinchilla.git
cd Chinchilla
```
### 2. Setup Virtual Environment
Create venv: ```python -m venv venv```

Activate (Linux / MacOS): ```source ./venv/bin/activate```

Activate (Windows): ```.\venv\Scripts\activate```

### 2. Install the requirements

```pip install -r requirements.txt```

### 3. Run the application
```python chinchilla.py```

### 4. Hack the application!
URL: http://127.0.0.1:8000/chinchilla

<img width="1347" height="802" alt="Screenshot 2025-07-11 at 14 01 04" src="https://github.com/user-attachments/assets/69ad8f77-388b-4147-aea0-d01bf459d314" />


Please note that it may take a while for the chatbot to generate a response, especially for the first few attempts.
